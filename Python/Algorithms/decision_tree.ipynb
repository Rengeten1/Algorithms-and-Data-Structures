{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary classification finding the optimal decision tree is NP-complete\n",
    "# as threre are ((2)^2)^n possible trees\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd43c8",
   "metadata": {},
   "source": [
    "#### What is NP-complete?\n",
    "NP-complete is a class of problems in computational complexity theory. A problem is NP-complete if:\n",
    "1. It is in NP (nondeterministic polynomial time), meaning that a solution can be verified in polynomial time.  \n",
    "2. It is as hard as the hardest problems in NP, meaning that if any NP-complete problem can be solved in polynomial time, then every problem in NP can also be solved in polynomial time.\n",
    "3. Any NP problem can be reduced to it in polynomial time, meaning that if you can solve one NP-complete problem efficiently, you can solve all NP problems efficiently.\n",
    "#### Examples of NP-complete problems\n",
    "1. **Traveling Salesman Problem (TSP)**: Given a list of cities and distances between them, find the shortest possible route that visits each city exactly once and returns to the origin city.\n",
    "2. **Knapsack Problem**: Given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.\n",
    "3. **Graph Coloring**: Given a graph, determine the minimum number of colors needed to color the vertices so that no two adjacent vertices share the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef197d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID3 algorithm uses entropy theory to find the most relevant attributes.\n",
    "# It is a greedy divide-and-conquer \n",
    "# which tests the most important attribute first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43513587",
   "metadata": {},
   "source": [
    "Entropy bit formula:\n",
    "$$\n",
    "H(X) = -\\sum_{i=1}^{n} p(x_i) \\log_2 p(x_i)\n",
    "$$\n",
    "where $(H(X))$ is the entropy of the random variable $(X)$, $(p(x_i))$ is the probability of each outcome $(x_i)$, and $(n)$ is the number of possible outcomes.\n",
    "\n",
    "Information gain formula:\n",
    "$$\n",
    "IG(Y|X) = H(Y) - H(Y|X)\n",
    "$$\n",
    "where $(IG(Y|X))$ is the information gain of \\(Y\\) given \\(X\\), \\(H(Y)\\) is the entropy of \\(Y\\), and \\(H(Y|X)\\) is the conditional entropy of \\(Y\\) given \\(X\\)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
